<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Learning the 1+2D Burgers Equation with DeepONets</title>

  <script>
    MathJax = {
      tex: { inlineMath: [['$', '$'], ['\\(', '\\)']] }
    };
  </script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Fira+Code:wght@400;500&family=Lora:ital,wght@0,400;0,600;1,400&display=swap" rel="stylesheet">

  <style>
    :root {
      --bg-color: #fdfdfd;
      --text-color: #2c2e33;
      --heading-color: #111111;
      --accent-color: #0366d6;
      --code-bg: #f6f8fa;
      --code-border: #e1e4e8;
      --border-color: #eaecef;
    }

    body {
      max-width: 800px;
      margin: 0 auto;
      padding: 60px 20px;
      font-family: 'Lora', serif; /* Serif font for a more editorial, long-form reading experience */
      line-height: 1.8;
      font-size: 18px;
      color: var(--text-color);
      background-color: var(--bg-color);
      -webkit-font-smoothing: antialiased;
    }

    header {
      text-align: center;
      margin-bottom: 70px;
      font-family: 'Inter', sans-serif;
    }

    h1 {
      font-size: 2.8em;
      font-weight: 800;
      color: var(--heading-color);
      line-height: 1.15;
      margin-bottom: 20px;
      letter-spacing: -0.04em;
    }

    .subtitle {
      font-size: 1.2em;
      color: #555;
      margin-bottom: 25px;
      font-weight: 500;
    }

    .author-info {
      font-size: 0.9em;
      color: #666;
      text-transform: uppercase;
      letter-spacing: 0.05em;
    }

    h2 {
      font-family: 'Inter', sans-serif;
      font-size: 1.8em;
      font-weight: 700;
      color: var(--heading-color);
      margin-top: 60px;
      margin-bottom: 25px;
    }

    h3 {
      font-family: 'Inter', sans-serif;
      font-size: 1.3em;
      font-weight: 600;
      color: var(--heading-color);
      margin-top: 40px;
      margin-bottom: 15px;
    }

    p {
      margin-bottom: 24px;
    }

    /* Code Block Styling */
    code {
      font-family: 'Fira Code', monospace;
      background-color: rgba(175, 184, 193, 0.2);
      padding: 0.2em 0.4em;
      border-radius: 4px;
      font-size: 85%;
    }

    pre {
      background-color: var(--code-bg);
      border: 1px solid var(--code-border);
      border-radius: 8px;
      padding: 24px;
      overflow-x: auto;
      font-size: 14px;
      line-height: 1.6;
      box-shadow: inset 0 1px 4px rgba(0,0,0,0.02);
      margin: 30px 0;
    }

    pre code {
      background-color: transparent;
      padding: 0;
      border-radius: 0;
      font-size: 100%;
    }

    /* Comments in code */
    .c { color: #6a737d; font-style: italic; }
    .k { color: #d73a49; font-weight: bold; }
    .n { color: #24292e; }
    .s { color: #032f62; }

    ul, ol {
      margin-bottom: 24px;
      padding-left: 20px;
    }

    li {
      margin-bottom: 10px;
    }

    img {
      max-width: 100%;
      height: auto;
      border-radius: 6px;
      margin: 40px 0 15px 0;
      border: 1px solid var(--border-color);
      display: block;
    }

    .image-caption {
      text-align: center;
      font-family: 'Inter', sans-serif;
      font-size: 0.85em;
      color: #666;
      margin-bottom: 40px;
      padding: 0 20px;
    }

    .highlight-box {
      background-color: #f0f7ff;
      border-left: 4px solid var(--accent-color);
      padding: 20px 25px;
      margin: 40px 0;
      border-radius: 0 8px 8px 0;
      font-family: 'Inter', sans-serif;
      font-size: 0.95em;
    }

    hr {
      height: 1px;
      background-color: var(--border-color);
      border: none;
      margin: 60px 0;
    }

    .math-block {
      padding: 10px 0;
      text-align: center;
      margin: 30px 0;
      overflow-x: auto;
    }
  </style>
</head>

<body>

  <header>
    <h1>Learning the 1+2D Burgers Equation with DeepONets</h1>
    <div class="subtitle">A deep dive into continuous operator learning, spatial bottlenecks, and predicting shock fronts in fluid dynamics.</div>
    <div class="author-info">
      Research under Prof. Anirbit Mukherjee | University of Manchester
    </div>
  </header>

  <p>
    If you spend enough time working with Partial Differential Equations (PDEs), you quickly realize a frustrating truth: solving them numerically is a massive computational bottleneck. Every time your initial conditions change—even slightly—you have to run your finite difference or finite element solvers from scratch, marching painstakingly through time steps to satisfy the Courant–Friedrichs–Lewy (CFL) condition.
  </p>

  <p>
    But what if we didn't have to solve the PDE step-by-step? What if a neural network could learn the underlying physics so well that it could map an entire 2D initial condition field directly to the continuous solution at <em>any</em> future point in time?
  </p>

  <p>
    This is the promise of <b>Deep Operator Networks (DeepONets)</b>. Instead of mapping a finite grid to a finite grid, we learn the continuous operator itself:
  </p>

  <div class="math-block">
    $$ \mathcal{G}: u_0(x,y) \rightarrow u(x,y,t) $$
  </div>

  <p>
    In this post, we'll walk through the code and the mathematical reasoning behind engineering a DeepONet to solve the 2D viscous Burgers equation. We'll look at why we designed a heavily bottlenecked 4-dimensional branch network, how we optimized data loading for a massive 819K-point spatiotemporal dataset, and what our 4x4 grid visualizations tell us about how neural networks perceive fluid shocks.
  </p>

  <hr>

  <h2>1. The Physics: Convection vs. Diffusion</h2>

  <p>
    The 2D viscous Burgers equation is a beautiful, deeply frustrating PDE. It is the quintessential testing ground for nonlinear fluid dynamics:
  </p>

  <div class="math-block">
    $$ \frac{\partial u}{\partial t} + u \cdot \nabla u = \nu \Delta u $$
  </div>

  <p>
    Notice the two competing forces on the right and left sides:
  </p>
  <ul>
    <li><b>$u \cdot \nabla u$ (Nonlinear Convection):</b> This term describes how the velocity field pushes itself. Because regions of high velocity catch up to regions of low velocity, this term constantly tries to create infinitely steep gradients—known as <em>shocks</em>.</li>
    <li><b>$\nu \Delta u$ (Diffusion):</b> Scaled by the kinematic viscosity $\nu$, the Laplacian acts as a smoothing agent, smearing out sharp gradients.</li>
  </ul>

  <p>
    Neural networks generally hate discontinuities. Approximating the sharp shock fronts generated by the convective term without triggering massive oscillations (similar to the Gibbs phenomenon in Fourier analysis) is the ultimate test for our operator architecture.
  </p>

  <hr>

  <h2>2. Generating the Ground Truth (and the Data Bottleneck)</h2>

  <p>
    Before we can train an operator, we need ground truth data. We generate random 2D initial conditions $u_0(x,y)$ on a $64 \times 64$ grid and use a finite difference solver to march them forward in time. 
  </p>

  <p>
    However, creating a robust training set requires sampling thousands of spatial and temporal points across many initial conditions. We ended up with a massive spatiotemporal dataset containing over <b>819,200 individual query points</b>.
  </p>

  <p>
    If you try to pass an 819K-point tensor directly into a PyTorch MLP to calculate the MSE loss, your GPU will immediately trigger a CUDA Out Of Memory (OOM) error. To solve this, we had to engineer a heavily optimized data pipeline.
  </p>

<pre><code><span class="c"># We cannot evaluate the entire spatiotemporal domain at once.</span>
<span class="c"># We chunk the data into manageable pieces for the trunk network.</span>
<span class="k">class</span> <span class="n">BurgersDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="n">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">u0_data</span><span class="p">,</span> <span class="n">coords_data</span><span class="p">,</span> <span class="n">solution_data</span><span class="p">):</span>
        <span class="c"># u0_data: (N_samples, 1, 64, 64)</span>
        <span class="c"># coords_data: (N_samples, N_points, 3) -> (x, y, t)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">u0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">u0_data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">coords</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">coords_data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">sol</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">solution_data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c"># During training, we optimized trunk processing by splitting the query points </span>
<span class="c"># into over 20,000 discrete chunks. This allows the model to compute gradients </span>
<span class="c"># efficiently across the 819K point space without memory spikes.</span>
</code></pre>

  <hr>

  <h2>3. The Architecture: Branch and Trunk</h2>

  <p>
    The brilliance of the DeepONet theorem (proposed by Lu et al., based on Chen & Chen's universal approximation theorem for operators) is that we can decouple the input function from the query coordinates. The final solution is simply a dot product:
  </p>

  <div class="math-block">
    $$ u_\theta(x,y,t) = \sum_{k=1}^{p} b_k(u_0)\, t_k(x,y,t) $$
  </div>

  <p>
    Think of it this way: The trunk network learns a universal set of <em>basis functions</em> ($t_k$) for the domain, while the branch network learns to look at the initial condition and predict the <em>coefficients</em> ($b_k$) to weigh those basis functions.
  </p>

  <h3>The Branch Network: Forcing a Bottleneck</h3>
  <p>
    Our initial condition is a $64 \times 64$ grid. We chose a CNN to process it because convection is driven by local spatial gradients, which convolutional kernels excel at detecting.
  </p>
  <p>
    However, the most crucial design choice here was the use of an <code>AdaptiveAvgPool2d</code> layer followed by a severe dimensionality reduction. We bottlenecked the output to a remarkably tight <b>4-dimensional latent space</b> ($p=4$). Why? Because an overly wide branch network tends to memorize the training grid rather than learning the generalized physical operator. Forcing the CNN to compress the entire $64 \times 64$ fluid state into just 4 numbers forces it to learn the most fundamental, invariant features of the initial wave profile.
  </p>

<pre><code><span class="k">class</span> <span class="n">BranchNet</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="n">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="n">4</span><span class="p">):</span> <span class="c"># The 4-dimensional bottleneck</span>
        <span class="n">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">convs</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">1</span><span class="p">,</span> <span class="n">16</span><span class="p">,</span> <span class="n">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">1</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="p">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">16</span><span class="p">,</span> <span class="n">32</span><span class="p">,</span> <span class="n">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">1</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="p">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">32</span><span class="p">,</span> <span class="n">64</span><span class="p">,</span> <span class="n">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">1</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="p">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">2</span><span class="p">)</span>
        <span class="p">)</span>
        
        <span class="c"># Adaptive pooling decouples the architecture from the input grid size.</span>
        <span class="c"># We compress spatial features to 2x2 regardless of input resolution.</span>
        <span class="n">self</span><span class="p">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="n">2</span><span class="p">,</span> <span class="n">2</span><span class="p">))</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">64</span> <span class="o">*</span> <span class="n">2</span> <span class="o">*</span> <span class="n">2</span><span class="p">,</span> <span class="n">128</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">128</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span> <span class="c"># Outputs [b_1, b_2, b_3, b_4]</span>
        <span class="p">)</span>
</code></pre>

  <h3>The Trunk Network: Mapping the Domain</h3>
  <p>
    While the branch is tightly bottlenecked, the trunk requires a bit more expressive capacity to map out the highly non-linear spatiotemporal domain. We paired our 4-dimensional branch with a <b>14-dimensional trunk</b>. The trunk processes the $(x, y, t)$ coordinates through several <code>Tanh</code> activations—we avoid ReLU here because we want our predicted basis functions to be continuously differentiable, just like the PDE solution itself.
  </p>

  <hr>

  <h2>4. Training Dynamics and Results</h2>

  <div class="highlight-box">
    By combining the 4-dim branch and 14-dim trunk, and optimizing the trunk processing of the 20K+ data chunks, we achieved highly stable convergence. The network reached a <b>minimum MSE loss of 0.0055</b> on the training set, and generalized exceptionally well to unseen initial conditions with less than 0.1% validation MSE.
  </div>

  <p>
    But loss numbers only tell half the story. To truly understand what the operator learned, we developed comprehensive $4 \times 4$ grid visualizations for error analysis.
  </p>

  <img src="assets/figures/prediction.png" alt="DeepONet Predictions 4x4 Grid" />
  <div class="image-caption">Figure 1: A 4x4 grid comparing the Ground Truth (top row) with the DeepONet continuous prediction (bottom row) at various time steps $t$. Notice how accurately the network predicts the steepening of the wave front over time.</div>

  <img src="assets/figures/error.png" alt="DeepONet MAE and L2 Error Maps" />
  <div class="image-caption">Figure 2: Absolute Error maps. Darker colors indicate higher error. The visualization reveals that the vast majority of the domain has near-zero error.</div>

  <h3>What the Visualizations Tell Us</h3>
  <p>
    When you examine the $4 \times 4$ error grids, a clear pattern emerges: the DeepONet's predictions are virtually flawless in the smooth regions of the fluid. The L2 and Mean Absolute Error (MAE) spike <em>exclusively</em> along the shock fronts—the exact regions where the convection term $u \cdot \nabla u$ dominates and gradients become near-vertical. 
  </p>
  <p>
    This is a known behavior in physics-informed and operator networks. It proves our network isn't just memorizing pixel patterns; it is actively attempting to balance the physical tension between convection and diffusion, struggling only where the underlying mathematics itself approaches a singularity.
  </p>

  <hr>

  <h2>5. Next Steps: Moving to Spherical Geometries</h2>

  <p>
    Solving the 1+2D Burgers equation on a Euclidean grid is a powerful proof of concept for neural operators. But many real-world physical systems—like global weather patterns or plasma containment—do not exist on flat planes.
  </p>
  <p>
    Our current research at the University of Manchester is expanding this architecture. We are replacing the standard Euclidean CNN branch with $SO(3)$-equivariant Spherical CNNs to solve intrinsic geometric PDEs, specifically the Laplace-Beltrami and Heat equations, directly on the surface of a two-sphere ($\mathbb{S}^2$).
  </p>

</body>
</html>
