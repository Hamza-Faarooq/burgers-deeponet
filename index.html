<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Learning the 1+2D Burgers Equation with DeepONets</title>

  <script>
    MathJax = {
      tex: { inlineMath: [['$', '$'], ['\\(', '\\)']] }
    };
  </script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Fira+Code:wght@400;500&family=Lora:ital,wght@0,400;0,600;1,400&display=swap" rel="stylesheet">

  <style>
    :root {
      --bg-color: #fdfdfd;
      --text-color: #2c2e33;
      --heading-color: #111111;
      --accent-color: #0366d6;
      --code-bg: #f6f8fa;
      --code-border: #e1e4e8;
      --border-color: #eaecef;
    }

    body {
      max-width: 800px;
      margin: 0 auto;
      padding: 60px 20px;
      font-family: 'Lora', serif; /* Serif font for a more editorial, long-form reading experience */
      line-height: 1.8;
      font-size: 18px;
      color: var(--text-color);
      background-color: var(--bg-color);
      -webkit-font-smoothing: antialiased;
    }

    header {
      text-align: center;
      margin-bottom: 70px;
      font-family: 'Inter', sans-serif;
    }

    h1 {
      font-size: 2.8em;
      font-weight: 800;
      color: var(--heading-color);
      line-height: 1.15;
      margin-bottom: 20px;
      letter-spacing: -0.04em;
    }

    .subtitle {
      font-size: 1.2em;
      color: #555;
      margin-bottom: 25px;
      font-weight: 500;
    }

    .author-info {
      font-size: 0.9em;
      color: #666;
      text-transform: uppercase;
      letter-spacing: 0.05em;
    }

    h2 {
      font-family: 'Inter', sans-serif;
      font-size: 1.8em;
      font-weight: 700;
      color: var(--heading-color);
      margin-top: 60px;
      margin-bottom: 25px;
    }

    h3 {
      font-family: 'Inter', sans-serif;
      font-size: 1.3em;
      font-weight: 600;
      color: var(--heading-color);
      margin-top: 40px;
      margin-bottom: 15px;
    }

    p {
      margin-bottom: 24px;
    }

    /* Code Block Styling */
    code {
      font-family: 'Fira Code', monospace;
      background-color: rgba(175, 184, 193, 0.2);
      padding: 0.2em 0.4em;
      border-radius: 4px;
      font-size: 85%;
    }

    pre {
      background-color: var(--code-bg);
      border: 1px solid var(--code-border);
      border-radius: 8px;
      padding: 24px;
      overflow-x: auto;
      font-size: 14px;
      line-height: 1.6;
      box-shadow: inset 0 1px 4px rgba(0,0,0,0.02);
      margin: 30px 0;
    }

    pre code {
      background-color: transparent;
      padding: 0;
      border-radius: 0;
      font-size: 100%;
    }

    /* Comments in code */
    .c { color: #6a737d; font-style: italic; }
    .k { color: #d73a49; font-weight: bold; }
    .n { color: #24292e; }
    .s { color: #032f62; }

    ul, ol {
      margin-bottom: 24px;
      padding-left: 20px;
    }

    li {
      margin-bottom: 10px;
    }

    img {
      max-width: 100%;
      height: auto;
      border-radius: 6px;
      margin: 40px 0 15px 0;
      border: 1px solid var(--border-color);
      display: block;
    }

    .image-caption {
      text-align: center;
      font-family: 'Inter', sans-serif;
      font-size: 0.85em;
      color: #666;
      margin-bottom: 40px;
      padding: 0 20px;
    }

    .highlight-box {
      background-color: #f0f7ff;
      border-left: 4px solid var(--accent-color);
      padding: 20px 25px;
      margin: 40px 0;
      border-radius: 0 8px 8px 0;
      font-family: 'Inter', sans-serif;
      font-size: 0.95em;
    }

    hr {
      height: 1px;
      background-color: var(--border-color);
      border: none;
      margin: 60px 0;
    }

    .math-block {
      padding: 10px 0;
      text-align: center;
      margin: 30px 0;
      overflow-x: auto;
    }
  </style>
</head>

<body>

  <header>
    <h1>Learning the 1+2D Burgers Equation with DeepONets</h1>
    <div class="subtitle">A deep dive into continuous operator learning, spatial bottlenecks, and predicting shock fronts in fluid dynamics.</div>
    <div class="author-info">
      Research under Prof. Anirbit Mukherjee | University of Manchester
    </div>
  </header>

  <p>
    If you spend enough time working with Partial Differential Equations (PDEs), you quickly realize a frustrating truth: solving them numerically is a massive computational bottleneck. Every time your initial conditions change—even slightly—you have to run your finite difference or finite element solvers from scratch, marching painstakingly through time steps to satisfy the Courant–Friedrichs–Lewy (CFL) condition.
  </p>

  <p>
    But what if we didn't have to solve the PDE step-by-step? What if a neural network could learn the underlying physics so well that it could map an entire 2D initial condition field directly to the continuous solution at <em>any</em> future point in time?
  </p>

  <p>
    This is the promise of <b>Deep Operator Networks (DeepONets)</b>. Instead of mapping a finite grid to a finite grid, we learn the continuous operator itself:
  </p>

  <div class="math-block">
    $$ \mathcal{G}: u_0(x,y) \rightarrow u(x,y,t) $$
  </div>

  <p>
    In this post, we'll walk through the code and the mathematical reasoning behind engineering a DeepONet to solve the 2D viscous Burgers equation. We'll look at why we designed a heavily bottlenecked 4-dimensional branch network, how we optimized data loading for a massive 819K-point spatiotemporal dataset, and what our 4x4 grid visualizations tell us about how neural networks perceive fluid shocks.
  </p>

  <hr>

  <h2>1. The Physics: Convection vs. Diffusion</h2>

  <p>
    The 2D viscous Burgers equation is a beautiful, deeply frustrating PDE. It is the quintessential testing ground for nonlinear fluid dynamics:
  </p>

  <div class="math-block">
    $$ \frac{\partial u}{\partial t} + u \cdot \nabla u = \nu \Delta u $$
  </div>

  <p>
    Notice the two competing forces on the right and left sides:
  </p>
  <ul>
    <li><b>$u \cdot \nabla u$ (Nonlinear Convection):</b> This term describes how the velocity field pushes itself. Because regions of high velocity catch up to regions of low velocity, this term constantly tries to create infinitely steep gradients—known as <em>shocks</em>.</li>
    <li><b>$\nu \Delta u$ (Diffusion):</b> Scaled by the kinematic viscosity $\nu$, the Laplacian acts as a smoothing agent, smearing out sharp gradients.</li>
  </ul>

  <p>
    Neural networks generally hate discontinuities. Approximating the sharp shock fronts generated by the convective term without triggering massive oscillations (similar to the Gibbs phenomenon in Fourier analysis) is the ultimate test for our operator architecture.
  </p>

  <hr>

  <h2>2. Generating the Ground Truth (and the Data Bottleneck)</h2>

  <p>
    Before we can train an operator, we need ground truth data. We generate random 2D initial conditions $u_0(x,y)$ on a $64 \times 64$ grid and use a finite difference solver to march them forward in time. 
  </p>

  <p>
    However, creating a robust training set requires sampling thousands of spatial and temporal points across many initial conditions. We ended up with a massive spatiotemporal dataset containing over <b>819,200 individual query points</b>.
  </p>

  <p>
    If you try to pass an 819K-point tensor directly into a PyTorch MLP to calculate the MSE loss, your GPU will immediately trigger a CUDA Out Of Memory (OOM) error. To solve this, we had to engineer a heavily optimized data pipeline.
  </p>

<pre><code><span class="c"># We cannot evaluate the entire spatiotemporal domain at once.</span>
<span class="c"># We chunk the data into manageable pieces for the trunk network.</span>
<span class="k">class</span> <span class="n">BurgersDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="n">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">u0_data</span><span class="p">,</span> <span class="n">coords_data</span><span class="p">,</span> <span class="n">solution_data</span><span class="p">):</span>
        <span class="c"># u0_data: (N_samples, 1, 64, 64)</span>
        <span class="c"># coords_data: (N_samples, N_points, 3) -> (x, y, t)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">u0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">u0_data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">coords</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">coords_data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">sol</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">solution_data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c"># During training, we optimized trunk processing by splitting the query points </span>
<span class="c"># into over 20,000 discrete chunks. This allows the model to compute gradients </span>
<span class="c"># efficiently across the 819K point space without memory spikes.</span>
</code></pre>

  <hr>

  <h2>3. The Architecture: Branch and Trunk</h2>

  <p>
    The brilliance of the DeepONet theorem (proposed by Lu et al., based on Chen & Chen's universal approximation theorem for operators) is that we can decouple the input function from the query coordinates. The final solution is simply a dot product:
  </p>

  <div class="math-block">
    $$ u_\theta(x,y,t) = \sum_{k=1}^{p} b_k(u_0)\, t_k(x,y,t) $$
  </div>

  <p>
    Think of it this way: The trunk network learns a universal set of <em>basis functions</em> ($t_k$) for the domain, while the branch network learns to look at the initial condition and predict the <em>coefficients</em> ($b_k$) to weigh those basis functions.
  </p>

  <h3>The Branch Network: Forcing a Bottleneck</h3>
  <p>
    Our initial condition is a $64 \times 64$ grid. We chose a CNN to process it because convection is driven by local spatial gradients, which convolutional kernels excel at detecting.
  </p>
  <p>
    However, the most crucial design choice here was the use of an <code>AdaptiveAvgPool2d</code> layer followed by a severe dimensionality reduction. We bottlenecked the output to a remarkably tight <b>4-dimensional latent space</b> ($p=4$). Why? Because an overly wide branch network tends to memorize the training grid rather than learning the generalized physical operator. Forcing the CNN to compress the entire $64 \times 64$ fluid state into just 4 numbers forces it to learn the most fundamental, invariant features of the initial wave profile.
  </p>

<pre><code><span class="k">class</span> <span class="n">BranchNet</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="n">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="n">4</span><span class="p">):</span> <span class="c"># The 4-dimensional bottleneck</span>
        <span class="n">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">convs</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">1</span><span class="p">,</span> <span class="n">16</span><span class="p">,</span> <span class="n">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">1</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="p">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">16</span><span class="p">,</span> <span class="n">32</span><span class="p">,</span> <span class="n">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">1</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="p">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">32</span><span class="p">,</span> <span class="n">64</span><span class="p">,</span> <span class="n">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">1</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="p">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">2</span><span class="p">)</span>
        <span class="p">)</span>
        
        <span class="c"># Adaptive pooling decouples the architecture from the input grid size.</span>
        <span class="c"># We compress spatial features to 2x2 regardless of input resolution.</span>
        <span class="n">self</span><span class="p">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="n">2</span><span class="p">,</span> <span class="n">2</span><span class="p">))</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">64</span> <span class="o">*</span> <span class="n">2</span> <span class="o">*</span> <span class="n">2</span><span class="p">,</span> <span class="n">128</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">128</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span> <span class="c"># Outputs [b_1, b_2, b_3, b_4]</span>
        <span class="p">)</span>
</code></pre>

  <h3>The Trunk Network: Mapping the Domain</h3>
  <p>
    While the branch is tightly bottlenecked, the trunk requires a bit more expressive capacity to map out the highly non-linear spatiotemporal domain. We paired our 4-dimensional branch with a <b>14-dimensional trunk</b>. The trunk processes the $(x, y, t)$ coordinates through several <code>Tanh</code> activations—we avoid ReLU here because we want our predicted basis functions to be continuously differentiable, just like the PDE solution itself.
  </p>

  <hr>







  <hr>

  <h2>1. Data Generation: The Numerical Ground Truth</h2>

  <p>
    Before a neural network can learn an operator, it needs a teacher. In our case, the teacher is a traditional numerical solver. We generate our ground truth data by solving the 2D viscous Burgers equation using the <b>Finite Difference Method (FDM)</b>.
  </p>

  <p>
    First, we create a variety of initial velocity fields, $u_0(x,y)$, using combinations of sinusoidal waves. This ensures our network sees a diverse set of wave interactions and gradients.
  </p>

<pre><code class="language-python"><span class="c"># Generating a smooth, periodic initial condition</span>
<span class="k">def</span> <span class="n">generate_initial_condition</span><span class="p">(</span><span class="n">nx</span><span class="p">,</span> <span class="n">ny</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">0</span><span class="p">,</span> <span class="n">1</span><span class="p">,</span> <span class="n">nx</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">0</span><span class="p">,</span> <span class="n">1</span><span class="p">,</span> <span class="n">ny</span><span class="p">)</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="c"># A combination of sines and cosines creates complex wave interactions</span>
    <span class="n">u0</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sin</span><span class="p">(</span><span class="n">2</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="o">*</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">cos</span><span class="p">(</span><span class="n">2</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="o">*</span><span class="n">Y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">u0</span>
</code></pre>

  <p>
    Next, we step this initial condition forward in time. We use <b>central differences</b> for the spatial derivatives (to capture the gradients accurately) and a <b>forward difference</b> for the time derivative (Euler stepping).
  </p>

<pre><code class="language-python"><span class="k">def</span> <span class="n">burgers_step</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">dx</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">dt</span><span class="p">):</span>
    <span class="c"># 1. Compute first-order spatial derivatives (Central Difference)</span>
    <span class="c"># This maps to the non-linear convection term: u * \nabla u</span>
    <span class="n">u_x</span> <span class="o">=</span> <span class="p">(</span><span class="n">u</span><span class="p">[:,</span><span class="n">2</span><span class="p">:]</span> <span class="o">-</span> <span class="n">u</span><span class="p">[:,:</span><span class="o">-</span><span class="n">2</span><span class="p">])</span> <span class="o">/</span> <span class="p">(</span><span class="n">2</span><span class="o">*</span><span class="n">dx</span><span class="p">)</span>
    <span class="n">u_y</span> <span class="o">=</span> <span class="p">(</span><span class="n">u</span><span class="p">[</span><span class="n">2</span><span class="p">:,:]</span> <span class="o">-</span> <span class="n">u</span><span class="p">[:</span><span class="o">-</span><span class="n">2</span><span class="p">,:])</span> <span class="o">/</span> <span class="p">(</span><span class="n">2</span><span class="o">*</span><span class="n">dy</span><span class="p">)</span>

    <span class="c"># 2. Compute the Laplacian (Second-order Central Difference)</span>
    <span class="c"># This maps to the diffusion term: \nu \Delta u</span>
    <span class="n">lap</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">(</span><span class="n">u</span><span class="p">[:,</span><span class="n">2</span><span class="p">:]</span> <span class="o">-</span> <span class="n">2</span><span class="o">*</span><span class="n">u</span><span class="p">[:,</span><span class="n">1</span><span class="p">:</span><span class="o">-</span><span class="n">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[:,:</span><span class="o">-</span><span class="n">2</span><span class="p">])</span> <span class="o">/</span> <span class="n">dx</span><span class="o">**</span><span class="n">2</span> <span class="o">+</span>
        <span class="p">(</span><span class="n">u</span><span class="p">[</span><span class="n">2</span><span class="p">:,:]</span> <span class="o">-</span> <span class="n">2</span><span class="o">*</span><span class="n">u</span><span class="p">[</span><span class="n">1</span><span class="p">:</span><span class="o">-</span><span class="n">1</span><span class="p">,:]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[:</span><span class="o">-</span><span class="n">2</span><span class="p">,:])</span> <span class="o">/</span> <span class="n">dy</span><span class="o">**</span><span class="n">2</span>
    <span class="p">)</span>

    <span class="c"># 3. Explicit Time Stepping</span>
    <span class="c"># We update the interior of the grid based on the PDE formulation</span>
    <span class="k">return</span> <span class="n">u</span><span class="p">[</span><span class="n">1</span><span class="p">:</span><span class="o">-</span><span class="n">1</span><span class="p">,</span><span class="n">1</span><span class="p">:</span><span class="o">-</span><span class="n">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">dt</span> <span class="o">*</span> <span class="p">(</span>
        <span class="o">-</span> <span class="n">u</span><span class="p">[</span><span class="n">1</span><span class="p">:</span><span class="o">-</span><span class="n">1</span><span class="p">,</span><span class="n">1</span><span class="p">:</span><span class="o">-</span><span class="n">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">u_x</span> <span class="o">+</span> <span class="n">u_y</span><span class="p">)</span> <span class="o">+</span> <span class="n">nu</span> <span class="o">*</span> <span class="n">lap</span>
    <span class="p">)</span>
</code></pre>

  <p>
    This generates extremely high-fidelity data. However, storing every pixel at every time step results in an explosion of data. For our training setup, this resulted in an <b>819,200-point spatiotemporal dataset</b>.
  </p>

  <hr>

  <h2>2. Dataset Engineering: Managing 819K Points</h2>

  <p>
    Feeding 819,200 coordinates into a GPU simultaneously will instantly cause an Out-of-Memory (OOM) error. To train our DeepONet, we must construct a PyTorch <code>Dataset</code> that feeds the model intelligently.
  </p>

  <p>
    A DeepONet requires three pieces of information for every forward pass:
  </p>
  <ol>
    <li><b>$u_0$:</b> The initial condition (Branch input).</li>
    <li><b>$(x,y,t)$:</b> The specific spatiotemporal coordinate we want to query (Trunk input).</li>
    <li><b>$u_{true}$:</b> The ground truth value at that exact coordinate (for calculating the loss).</li>
  </ol>

<pre><code class="language-python"><span class="k">class</span> <span class="n">BurgersDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="n">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">u0_list</span><span class="p">,</span> <span class="n">coord_list</span><span class="p">,</span> <span class="n">solution_list</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">u0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">u0_list</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">coords</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">coord_list</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">sol</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">solution_list</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="k">def</span> <span class="n">__len__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">sol</span><span class="p">)</span>

    <span class="k">def</span> <span class="n">__getitem__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">u0</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">self</span><span class="p">.</span><span class="n">coords</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">self</span><span class="p">.</span><span class="n">sol</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
</code></pre>

  <div class="highlight-box">
    <b>The Chunking Optimization:</b> Instead of passing the whole domain to the trunk network, we split the 819K coordinates into over 20,000 discrete chunks during training. This keeps the VRAM usage flat while allowing the network to sweep across the entire spatiotemporal volume efficiently.
  </div>

  <hr>

  <h2>3. The Branch Network: The Spatial Encoder</h2>

  <p>
    The Branch network is responsible for "looking" at the initial condition $u_0(x,y)$ and distilling it into a set of latent coefficients. 
  </p>
  <p>
    Because the input is a 2D grid, a Multi-Layer Perceptron (MLP) would destroy the spatial relationships between neighboring pixels. Instead, we use a Convolutional Neural Network (CNN). The CNN acts as a feature extractor, looking for the local gradients and peaks that will eventually evolve into shock fronts.
  </p>
  <p>
    However, the magic happens at the <code>AdaptiveAvgPool2d</code> layer. We aggressively bottleneck the network, compressing the feature maps down to a mere <b>4-dimensional vector</b>. This forces the model to learn the invariant physical properties of the initial condition rather than just memorizing pixel values.
  </p>

<pre><code class="language-python"><span class="k">class</span> <span class="n">BranchNet</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="n">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="n">4</span><span class="p">):</span> <span class="c"># 4-dimensional bottleneck</span>
        <span class="n">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="c"># CNN blocks to extract spatial hierarchies</span>
        <span class="n">self</span><span class="p">.</span><span class="n">convs</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">1</span><span class="p">,</span> <span class="n">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">1</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="p">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">16</span><span class="p">,</span> <span class="n">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">1</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="p">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">2</span><span class="p">),</span>
        <span class="p">)</span>
        
        <span class="c"># Decouples the network from the exact input grid size</span>
        <span class="n">self</span><span class="p">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="n">2</span><span class="p">,</span> <span class="n">2</span><span class="p">))</span>
        
        <span class="c"># Final projection to the latent basis</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">32</span> <span class="o">*</span> <span class="n">2</span> <span class="o">*</span> <span class="n">2</span><span class="p">,</span> <span class="n">64</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">64</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span> 
        <span class="p">)</span>

    <span class="k">def</span> <span class="n">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">convs</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre>

  <hr>

  <h2>4. The Trunk Network: The Coordinate Mapper</h2>

  <p>
    The Trunk network is tasked with learning the spatial-temporal basis functions. It takes the continuous coordinates $(x,y,t)$ and maps them to a higher-dimensional space.
  </p>

  <p>
    Notice the activation function: we use <b>Tanh</b> instead of ReLU. A neural network with ReLU activations is piecewise linear, meaning its second derivative is zero everywhere (and undefined at the hinges). Since the Burgers equation relies on a smooth second spatial derivative (the Laplacian $\Delta u$), we must use a smooth, continuously differentiable activation function like Tanh to ensure the learned operator respects the physical continuity of fluid flow. 
  </p>

  <p>
    In our optimized runs, we expanded the Trunk to a <b>14-dimensional output</b> to give the coordinate basis enough capacity to represent complex shock geometries.
  </p>

<pre><code class="language-python"><span class="k">class</span> <span class="n">TrunkNet</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="n">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="n">3</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="n">128</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="n">14</span><span class="p">):</span>
        <span class="n">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Tanh</span><span class="p">(),</span> <span class="c"># Smooth activations for continuous physics</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Tanh</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span> <span class="c"># Must map to the Trunk basis dimension</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="n">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">coords</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">net</span><span class="p">(</span><span class="n">coords</span><span class="p">)</span>
</code></pre>

  <hr>

  <h2>5. The DeepONet Forward Pass: The Dot Product</h2>

  <p>
    The final architecture is surprisingly elegant. We pass the initial condition through the Branch to get the coefficients $b$, and the coordinates through the Trunk to get the basis functions $t$. 
  </p>
  
  <p>
    The prediction at any point in space and time is simply the dot product of these two vectors: $u(x,y,t) = b \cdot t$.
  </p>

<pre><code class="language-python"><span class="k">class</span> <span class="n">DeepONet</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="n">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">branch</span><span class="p">,</span> <span class="n">trunk</span><span class="p">):</span>
        <span class="n">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">branch</span> <span class="o">=</span> <span class="n">branch</span>
        <span class="n">self</span><span class="p">.</span><span class="n">trunk</span> <span class="o">=</span> <span class="n">trunk</span>

    <span class="k">def</span> <span class="n">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">u0</span><span class="p">,</span> <span class="n">coords</span><span class="p">):</span>
        <span class="c"># Evaluate branch logic -> output shape: (batch_size, p)</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">branch</span><span class="p">(</span><span class="n">u0</span><span class="p">)</span> 
        
        <span class="c"># Evaluate trunk logic -> output shape: (batch_size, num_points, p)</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">trunk</span><span class="p">(</span><span class="n">coords</span><span class="p">)</span> 
        
        <span class="c"># Reshape b to broadcast across the num_points dimension</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">b</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">1</span><span class="p">)</span> 
        
        <span class="c"># The final Operator prediction is the sum over the latent dimension (dot product)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sum</span><span class="p">(</span><span class="n">b</span> <span class="o">*</span> <span class="n">t</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="n">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="n">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">pred</span>
</code></pre>

  <hr>

  <h2>6. The Training Loop: Minimizing the Residuals</h2>

  <p>
    Training a DeepONet is fundamentally a regression problem. We use the <b>Adam optimizer</b> to minimize the Mean Squared Error (MSE) between our network's continuous prediction and the discrete ground truth data generated by our FDM solver.
  </p>

<pre><code class="language-python"><span class="c"># Initialize model, optimizer, and loss function</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">DeepONet</span><span class="p">(</span><span class="n">BranchNet</span><span class="p">(),</span> <span class="n">TrunkNet</span><span class="p">()).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">MSELoss</span><span class="p">()</span>

<span class="c"># The Training Loop</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">0</span>
    
    <span class="k">for</span> <span class="n">u0_batch</span><span class="p">,</span> <span class="n">coord_batch</span><span class="p">,</span> <span class="n">true_batch</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="n">u0_batch</span><span class="p">,</span> <span class="n">coord_batch</span><span class="p">,</span> <span class="n">true_batch</span> <span class="o">=</span> <span class="n">u0_batch</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">coord_batch</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">true_batch</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c"># Forward Pass</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">u0_batch</span><span class="p">,</span> <span class="n">coord_batch</span><span class="p">).</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">true_batch</span><span class="p">)</span>
        
        <span class="c"># Backpropagation</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
        
        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="n">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">50</span> <span class="o">==</span> <span class="n">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s">f"Epoch {epoch+1} | MSE Loss: {total_loss/len(train_loader):.6f}"</span><span class="p">)</span>
</code></pre>

  <p>
    Through this setup, the loss consistently dropped, eventually stabilizing at an exceptional <b>0.0055 MSE</b>. The network had successfully learned the continuous operator mapping for the 1+2D viscous Burgers equation.
  </p>







  






  
  <h2>4. Training Dynamics and Results</h2>

  <div class="highlight-box">
    By combining the 4-dim branch and 14-dim trunk, and optimizing the trunk processing of the 20K+ data chunks, we achieved highly stable convergence. The network reached a <b>minimum MSE loss of 0.0055</b> on the training set, and generalized exceptionally well to unseen initial conditions with less than 0.1% validation MSE.
  </div>

  <p>
    But loss numbers only tell half the story. To truly understand what the operator learned, we developed comprehensive $4 \times 4$ grid visualizations for error analysis.
  </p>

  <img src="assets/figures/prediction.png" alt="DeepONet Predictions 4x4 Grid" />
  <div class="image-caption">Figure 1: A 4x4 grid comparing the Ground Truth (top row) with the DeepONet continuous prediction (bottom row) at various time steps $t$. Notice how accurately the network predicts the steepening of the wave front over time.</div>

  <img src="assets/figures/error.png" alt="DeepONet MAE and L2 Error Maps" />
  <div class="image-caption">Figure 2: Absolute Error maps. Darker colors indicate higher error. The visualization reveals that the vast majority of the domain has near-zero error.</div>

  <h3>What the Visualizations Tell Us</h3>
  <p>
    When you examine the $4 \times 4$ error grids, a clear pattern emerges: the DeepONet's predictions are virtually flawless in the smooth regions of the fluid. The L2 and Mean Absolute Error (MAE) spike <em>exclusively</em> along the shock fronts—the exact regions where the convection term $u \cdot \nabla u$ dominates and gradients become near-vertical. 
  </p>
  <p>
    This is a known behavior in physics-informed and operator networks. It proves our network isn't just memorizing pixel patterns; it is actively attempting to balance the physical tension between convection and diffusion, struggling only where the underlying mathematics itself approaches a singularity.
  </p>

  <hr>

  <h2>5. Next Steps: Moving to Spherical Geometries</h2>

  <p>
    Solving the 1+2D Burgers equation on a Euclidean grid is a powerful proof of concept for neural operators. But many real-world physical systems—like global weather patterns or plasma containment—do not exist on flat planes.
  </p>
  <p>
    Our current research at the University of Manchester is expanding this architecture. We are replacing the standard Euclidean CNN branch with $SO(3)$-equivariant Spherical CNNs to solve intrinsic geometric PDEs, specifically the Laplace-Beltrami and Heat equations, directly on the surface of a two-sphere ($\mathbb{S}^2$).
  </p>

</body>
</html>
