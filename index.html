<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Learning the 1+2D Burgers Equation with DeepONets</title>

  <script>
    MathJax = {
      tex: { inlineMath: [['$', '$'], ['\\(', '\\)']] }
    };
  </script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Fira+Code:wght@400;500&display=swap" rel="stylesheet">

  <style>
    :root {
      --bg-color: #fafafa;
      --text-color: #333333;
      --heading-color: #111111;
      --accent-color: #0366d6;
      --code-bg: #f6f8fa;
      --code-border: #e1e4e8;
      --border-color: #eaecef;
    }

    body {
      max-width: 850px;
      margin: 0 auto;
      padding: 40px 20px;
      font-family: 'Inter', -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif;
      line-height: 1.7;
      font-size: 17px;
      color: var(--text-color);
      background-color: var(--bg-color);
      -webkit-font-smoothing: antialiased;
    }

    header {
      text-align: center;
      margin-bottom: 60px;
    }

    h1 {
      font-size: 2.5em;
      font-weight: 700;
      color: var(--heading-color);
      line-height: 1.2;
      margin-bottom: 15px;
      letter-spacing: -0.03em;
    }

    .subtitle {
      font-size: 1.2em;
      color: #666;
      margin-bottom: 20px;
    }

    .author-info {
      font-size: 0.95em;
      color: #555;
      font-style: italic;
    }

    h2 {
      font-size: 1.8em;
      font-weight: 600;
      color: var(--heading-color);
      margin-top: 50px;
      margin-bottom: 20px;
      padding-bottom: 8px;
      border-bottom: 1px solid var(--border-color);
    }

    h3 {
      font-size: 1.3em;
      font-weight: 600;
      color: var(--heading-color);
      margin-top: 35px;
      margin-bottom: 15px;
    }

    p {
      margin-bottom: 20px;
    }

    /* Code Block Styling */
    code {
      font-family: 'Fira Code', ui-monospace, SFMono-Regular, Consolas, "Liberation Mono", Menlo, monospace;
      background-color: rgba(175, 184, 193, 0.2);
      padding: 0.2em 0.4em;
      border-radius: 6px;
      font-size: 85%;
    }

    pre {
      background-color: var(--code-bg);
      border: 1px solid var(--code-border);
      border-radius: 8px;
      padding: 20px;
      overflow-x: auto;
      font-size: 14px;
      line-height: 1.5;
      box-shadow: 0 1px 3px rgba(0,0,0,0.02);
    }

    pre code {
      background-color: transparent;
      padding: 0;
      border-radius: 0;
      font-size: 100%;
    }

    ul, ol {
      margin-bottom: 20px;
      padding-left: 30px;
    }

    li {
      margin-bottom: 8px;
    }

    img {
      max-width: 100%;
      height: auto;
      border-radius: 8px;
      margin: 30px 0;
      box-shadow: 0 4px 12px rgba(0,0,0,0.08);
      display: block;
    }

    .image-caption {
      text-align: center;
      font-size: 0.9em;
      color: #666;
      margin-top: -15px;
      margin-bottom: 30px;
      font-style: italic;
    }

    .highlight-box {
      background-color: #e8f4fd;
      border-left: 4px solid var(--accent-color);
      padding: 15px 20px;
      margin: 30px 0;
      border-radius: 0 8px 8px 0;
    }

    hr {
      height: 1px;
      background-color: var(--border-color);
      border: none;
      margin: 50px 0;
    }

    /* Mathematical emphasis */
    .math-block {
      background-color: #ffffff;
      padding: 15px;
      border-radius: 8px;
      border: 1px solid var(--border-color);
      text-align: center;
      margin: 20px 0;
      box-shadow: 0 1px 2px rgba(0,0,0,0.02);
    }
  </style>
</head>

<body>

  <header>
    <h1>Learning the 1+2D Burgers Equation with DeepONets</h1>
    <div class="subtitle">A Deep Dive into Spatiotemporal Neural Operator Learning</div>
    <div class="author-info">
      Research Project under Prof. Anirbit Mukherjee<br>
      University of Manchester | <a href="https://github.com/Vision-jarvis/DeepONet-Project" style="color: #0366d6; text-decoration: none;">GitHub Repository</a>
    </div>
  </header>

  <p>
    This post explores how neural networks can learn to approximate complex solution operators for partial differential equations (PDEs). Specifically, we detail the engineering of a <b>Deep Operator Network (DeepONet)</b> to solve the two-dimensional viscous Burgers equation over time (1+2D).
  </p>

  <p>
    Instead of relying on expensive, iterative numerical solvers (like finite differences) every time an initial condition changes, we train a neural network to learn the continuous mapping from the initial state directly to the full spatiotemporal solution:
  </p>

  <div class="math-block">
    $$ \mathcal{G}: u_0(x,y) \rightarrow u(x,y,t) $$
  </div>

  <p>
    Once trained, this model acts as a surrogate, capable of instantly predicting the fluid's evolution for entirely unseen initial conditions.
  </p>

  <hr>

  <h2>1. The Mathematics: 2D Viscous Burgers Equation</h2>

  <p>
    The Burgers equation is a fundamental partial differential equation occurring in various areas of applied mathematics, such as fluid mechanics, nonlinear acoustics, and gas dynamics. It is often used as a simplified model for turbulence and shock wave formation. Our target is the 2D viscous form:
  </p>

  <div class="math-block">
    $$ \frac{\partial u}{\partial t} + u \cdot \nabla u = \nu \Delta u $$
  </div>

  <p>Where:</p>
  <ul>
    <li>$u(x,y,t)$ is the velocity field varying in space and time.</li>
    <li>$\nu$ is the kinematic viscosity (controlling the diffusion).</li>
    <li>$u \cdot \nabla u$ represents the nonlinear convection term (causing wave steepening and shocks).</li>
    <li>$\Delta u$ represents the diffusion term (smoothing the solution).</li>
  </ul>

  <p>
    This equation is notoriously difficult to model accurately due to the interplay between the nonlinear convection (which wants to create discontinuous shocks) and the viscous diffusion (which smooths them out). It serves as an excellent, rigorous benchmark for neural operator architectures.
  </p>

  <hr>

  <h2>2. Architectural Design: The DeepONet</h2>

  <p>
    The standard approach to predicting a physical system is to map a discrete grid to another discrete grid (e.g., standard CNNs). DeepONets, however, learn a mesh-free, continuous operator. The architecture fundamentally splits the problem into two parallel networks:
  </p>

  <div class="highlight-box">
    <b>Key Architecture Specs:</b> In this project, we engineered a DeepONet featuring a custom 4-dimensional branch network and a 14-dimensional trunk network, specifically optimized to handle a massive 819,200-point spatiotemporal dataset.
  </div>

  <h3>The Branch Network (Encoding the Function)</h3>
  <p>
    The Branch network ingests the input function—in our case, the 2D initial condition $u_0(x,y)$ discretized on a $64 \times 64$ grid. Because the input is spatial, we designed a Convolutional Neural Network (CNN) feature extractor followed by an <code>AdaptiveAvgPool2d</code> layer to compress the spatial information down to a fixed size before flattening.
  </p>

<pre><code class="language-python">class BranchNet(nn.Module):
    def __init__(self, output_dim):
        super(BranchNet, self).__init__()
        # CNN to extract spatial features from the 64x64 initial condition
        self.conv_layers = nn.Sequential(
            nn.Conv2d(1, 16, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2), # Output: 16 x 32 x 32
            
            nn.Conv2d(16, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2), # Output: 32 x 16 x 16
            
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2)  # Output: 64 x 8 x 8
        )
        
        # Adaptive pooling to handle potential varying input sizes 
        # and compress down to a 2x2 spatial dimension
        self.adaptive_pool = nn.AdaptiveAvgPool2d((2, 2))
        
        # Flattened size: 64 channels * 2 * 2 = 256
        self.fc_layers = nn.Sequential(
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, output_dim) # Output matches Trunk dimension (e.g., 4)
        )

    def forward(self, x):
        # x shape: (batch_size, 1, 64, 64)
        x = self.conv_layers(x)
        x = self.adaptive_pool(x)
        x = torch.flatten(x, 1)
        x = self.fc_layers(x)
        return x</code></pre>

  <h3>The Trunk Network (Encoding the Domain)</h3>
  <p>
    The Trunk network ingests the continuous spatiotemporal query coordinates $(x, y, t)$. It is a standard Multi-Layer Perceptron (MLP) that outputs a set of basis functions evaluated at those coordinates. We utilized a 14-dimensional trunk in our optimized runs.
  </p>

<pre><code class="language-python">class TrunkNet(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(TrunkNet, self).__init__()
        # MLP processing the (x, y, t) coordinates
        self.fc_layers = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.Tanh(), # Tanh often works well for coordinate networks
            nn.Linear(hidden_dim, hidden_dim),
            nn.Tanh(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.Tanh(),
            nn.Linear(hidden_dim, output_dim) # Output matches Branch dimension (e.g., 14)
        )

    def forward(self, x):
        # x shape: (batch_size, num_points, 3) where 3 is (x,y,t)
        return self.fc_layers(x)</code></pre>

  <h3>The DeepONet Integration</h3>
  <p>
    The final prediction is simply the dot product of the branch output (the coefficients) and the trunk output (the basis functions):
  </p>

  <div class="math-block">
    $$ u_\theta(x,y,t) = \sum_{k=1}^{p} b_k(u_0)\, t_k(x,y,t) $$
  </div>

<pre><code class="language-python">class DeepONet(nn.Module):
    def __init__(self, branch_net, trunk_net):
        super(DeepONet, self).__init__()
        self.branch = branch_net
        self.trunk = trunk_net

    def forward(self, u0, coords):
        # u0: (batch_size, 1, 64, 64)
        # coords: (batch_size, num_points, 3)
        branch_out = self.branch(u0) # Shape: (batch_size, p)
        trunk_out = self.trunk(coords) # Shape: (batch_size, num_points, p)
        
        # Expand branch output to match num_points and compute dot product
        branch_out = branch_out.unsqueeze(1) # (batch_size, 1, p)
        pred = torch.sum(branch_out * trunk_out, dim=-1) # (batch_size, num_points)
        return pred</code></pre>

  <hr>

  <h2>3. Data Generation and Massively Scalable Processing</h2>

  <p>
    Generating the ground truth data involved solving the PDE numerically using finite differences over a fine grid. However, the real challenge was processing the resulting dataset. 
  </p>
  <p>
    We constructed a pipeline to handle a spatiotemporal dataset containing <b>819,200 data points</b>. To make training feasible and prevent memory bottlenecks, we implemented a sophisticated chunking mechanism, dividing the data into over <b>20,000 discrete chunks</b> for optimized trunk processing during training.
  </p>

<pre><code class="language-python"># Example of the custom Dataset class handling the chunking
class BurgersDataset(Dataset):
    def __init__(self, X_branch, X_trunk, y_data):
        self.X_branch = torch.tensor(X_branch, dtype=torch.float32)
        self.X_trunk = torch.tensor(X_trunk, dtype=torch.float32)
        self.y_data = torch.tensor(y_data, dtype=torch.float32)
        
    def __len__(self):
        return len(self.X_branch)
        
    def __getitem__(self, idx):
        # Returns the 64x64 initial condition, the (x,y,t) coords, and the true u(x,y,t)
        return self.X_branch[idx], self.X_trunk[idx], self.y_data[idx]

# In the training loop, the data is processed in manageable batches
# to optimize memory usage across the 819K point space.
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)</code></pre>

  <hr>

  <h2>4. Training and Optimization</h2>

  <p>
    We utilized the Adam optimizer with a learning rate scheduler to carefully navigate the loss landscape. The model was trained using Mean Squared Error (MSE) against the high-resolution numerical simulations.
  </p>

  <div class="highlight-box">
    <b>Achievement:</b> Through architecture refinement and optimal batch processing, the model converged beautifully, achieving a minimum MSE loss of <b>0.0055</b> on the training set and maintaining a validation MSE of less than <b>0.1%</b>.
  </div>

  <hr>

  <h2>5. Visualizing the Operator's Performance</h2>

  <p>
    To rigorously evaluate the model, we didn't just look at the loss numbers. We developed comprehensive $4 \times 4$ grid visualizations to analyze test samples side-by-side with L2 errors and Mean Absolute Error (MAE) metrics.
  </p>
  
  <p>
    These visualizations confirmed that the network successfully learned to capture the nonlinear convection dynamics and generalization to unseen initial conditions, accurately predicting the regions where steep gradients (shocks) begin to form.
  </p>

  <img src="assets/figures/prediction.png" alt="DeepONet Predictions vs Ground Truth for Burgers Equation" />
  <div class="image-caption">Figure 1: Comparison of Ground Truth numerical solutions vs DeepONet predictions across different time steps.</div>

  <img src="assets/figures/error.png" alt="Absolute Error Map" />
  <div class="image-caption">Figure 2: Absolute error maps showing localized discrepancies, primarily concentrated near steep shock fronts.</div>

  <hr>

  <h2>6. Conclusion and Future Directions</h2>

  <p>
    This project successfully demonstrates that neural operators, specifically DeepONets, can serve as highly accurate and incredibly fast surrogate models for complex, nonlinear 1+2D PDEs like the Burgers equation. 
  </p>

  <p>
    Having established this baseline and developed a scalable data pipeline, our research is now moving towards even more complex geometric domains. We are currently adapting these operator learning techniques—incorporating $SO(3)$-equivariant spherical CNNs into the branch network—to solve intrinsic geometric PDEs, such as the Heat Equation, directly on the two-sphere ($\mathbb{S}^2$).
  </p>

</body>
</html>
