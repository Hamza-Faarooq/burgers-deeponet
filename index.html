<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Learning the 1+2D Burgers Equation with DeepONets</title>

  <script>
    MathJax = {
      tex: { inlineMath: [['$', '$'], ['\\(', '\\)']] }
    };
  </script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Fira+Code:wght@400;500&family=Lora:ital,wght@0,400;0,600;1,400&display=swap" rel="stylesheet">

  <style>
    :root {
      --bg-color: #fdfdfd;
      --text-color: #2c2e33;
      --heading-color: #111111;
      --accent-color: #0366d6;
      --code-bg: #f6f8fa;
      --code-border: #e1e4e8;
      --border-color: #eaecef;
    }

    body {
      max-width: 800px;
      margin: 0 auto;
      padding: 60px 20px;
      font-family: 'Lora', serif;
      line-height: 1.8;
      font-size: 18px;
      color: var(--text-color);
      background-color: var(--bg-color);
      -webkit-font-smoothing: antialiased;
    }

    header {
      text-align: center;
      margin-bottom: 70px;
      font-family: 'Inter', sans-serif;
    }

    h1 {
      font-size: 2.8em;
      font-weight: 800;
      color: var(--heading-color);
      line-height: 1.15;
      margin-bottom: 20px;
      letter-spacing: -0.04em;
    }

    .subtitle {
      font-size: 1.2em;
      color: #555;
      margin-bottom: 25px;
      font-weight: 500;
    }

    .author-info {
      font-size: 0.9em;
      color: #666;
      text-transform: uppercase;
      letter-spacing: 0.05em;
    }

    h2 {
      font-family: 'Inter', sans-serif;
      font-size: 1.8em;
      font-weight: 700;
      color: var(--heading-color);
      margin-top: 60px;
      margin-bottom: 25px;
    }

    h3 {
      font-family: 'Inter', sans-serif;
      font-size: 1.3em;
      font-weight: 600;
      color: var(--heading-color);
      margin-top: 40px;
      margin-bottom: 15px;
    }

    p {
      margin-bottom: 24px;
    }

    /* Code Block Styling */
    code {
      font-family: 'Fira Code', monospace;
      background-color: rgba(175, 184, 193, 0.2);
      padding: 0.2em 0.4em;
      border-radius: 4px;
      font-size: 85%;
    }

    pre {
      background-color: var(--code-bg);
      border: 1px solid var(--code-border);
      border-radius: 8px;
      padding: 24px;
      overflow-x: auto;
      font-size: 14px;
      line-height: 1.6;
      box-shadow: inset 0 1px 4px rgba(0,0,0,0.02);
      margin: 30px 0;
    }

    pre code {
      background-color: transparent;
      padding: 0;
      border-radius: 0;
      font-size: 100%;
    }

    .c { color: #6a737d; font-style: italic; }
    .k { color: #d73a49; font-weight: bold; }
    .n { color: #24292e; }
    .s { color: #032f62; }

    ul, ol {
      margin-bottom: 24px;
      padding-left: 20px;
    }

    li {
      margin-bottom: 10px;
    }

    img {
      max-width: 100%;
      height: auto;
      border-radius: 6px;
      margin: 40px 0 15px 0;
      border: 1px solid var(--border-color);
      display: block;
    }

    .image-caption {
      text-align: center;
      font-family: 'Inter', sans-serif;
      font-size: 0.85em;
      color: #666;
      margin-bottom: 40px;
      padding: 0 20px;
    }

    .highlight-box {
      background-color: #f0f7ff;
      border-left: 4px solid var(--accent-color);
      padding: 20px 25px;
      margin: 40px 0;
      border-radius: 0 8px 8px 0;
      font-family: 'Inter', sans-serif;
      font-size: 0.95em;
    }

    hr {
      height: 1px;
      background-color: var(--border-color);
      border: none;
      margin: 60px 0;
    }

    .math-block {
      padding: 10px 0;
      text-align: center;
      margin: 30px 0;
      overflow-x: auto;
    }
  </style>
</head>

<body>

  <header>
    <h1>Learning the 1+2D Burgers Equation with DeepONets</h1>
    <div class="subtitle">A deep dive into continuous operator learning, spatial bottlenecks, and predicting shock fronts in fluid dynamics.</div>
    <div class="author-info">
      Research under Prof. Anirbit Mukherjee | University of Manchester
    </div>
  </header>

  <p>
    If you spend enough time working with Partial Differential Equations (PDEs), you quickly realize a frustrating truth: solving them numerically is a massive computational bottleneck. Every time your initial conditions change—even slightly—you have to run your finite difference or finite element solvers from scratch, marching painstakingly through time steps to satisfy the Courant–Friedrichs–Lewy (CFL) condition.
  </p>

  <p>
    But what if we didn't have to solve the PDE step-by-step? What if a neural network could learn the underlying physics so well that it could map an entire 2D initial condition field directly to the continuous solution at <em>any</em> future point in time?
  </p>

  <p>
    This is the promise of <b>Deep Operator Networks (DeepONets)</b>. Instead of mapping a finite grid to a finite grid, we learn the continuous operator itself:
  </p>

  <div class="math-block">
    $$ \mathcal{G}: u_0(x,y) \rightarrow u(x,y,t) $$
  </div>

  <p>
    In this post, we'll walk through the code and the mathematical reasoning behind engineering a DeepONet to solve the 2D viscous Burgers equation. We'll look at why we designed a heavily bottlenecked branch network, how we optimized data loading for a massive 819K-point spatiotemporal dataset, and what our 4x4 grid visualizations tell us about how neural networks perceive fluid shocks.
  </p>

  <hr>

  <h2>1. The Physics: Convection vs. Diffusion</h2>

  <p>
    The 2D viscous Burgers equation is a beautiful, deeply frustrating PDE. It is the quintessential testing ground for nonlinear fluid dynamics:
  </p>

  <div class="math-block">
    $$ \frac{\partial u}{\partial t} + u \cdot \nabla u = \nu \Delta u $$
  </div>

  <p>
    Notice the two competing forces on the right and left sides:
  </p>
  <ul>
    <li><b>$u \cdot \nabla u$ (Nonlinear Convection):</b> This term describes how the velocity field pushes itself. Because regions of high velocity catch up to regions of low velocity, this term constantly tries to create infinitely steep gradients.</li>
    <li><b>$\nu \Delta u$ (Diffusion):</b> Scaled by the kinematic viscosity $\nu$, the Laplacian acts as a smoothing agent, smearing out sharp gradients.</li>
  </ul>

  <h3>The "Traffic Jam" Analogy</h3>
  <p>
    If the math looks abstract, think of the Burgers equation as a model of highway traffic. 
  </p>
  <p>
    The convective term means that the speed of the wave depends on the wave's height itself. Faster cars (higher velocity) at the back will eventually catch up to slower cars in the front. This causes the wave to steepen, eventually trying to form an infinitely sharp vertical drop—a <b>shock wave</b> (or a sudden, brutal traffic jam).
  </p>
  <p>
    However, the diffusion term acts like drivers tapping their brakes to maintain a safe distance. It smears out the sharp edges. The exact shape of the fluid flow over time is a constant, delicate tug-of-war between these two effects. Neural networks generally hate discontinuities, making this equation the ultimate test for our operator architecture.
  </p>

  <hr>

  <h2>2. Data Generation: The Numerical Ground Truth</h2>

  <p>
    Before a neural network can learn an operator, it needs a teacher. We generate our ground truth data by solving the 2D viscous Burgers equation using the <b>Finite Difference Method (FDM)</b>. We use central differences for the spatial derivatives and a forward difference for the time derivative (Euler stepping).
  </p>

<pre><code class="language-python"><span class="k">def</span> <span class="n">burgers_step</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">dx</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">dt</span><span class="p">):</span>
    <span class="c"># 1. Compute first-order spatial derivatives (Central Difference)</span>
    <span class="n">u_x</span> <span class="o">=</span> <span class="p">(</span><span class="n">u</span><span class="p">[:,</span><span class="n">2</span><span class="p">:]</span> <span class="o">-</span> <span class="n">u</span><span class="p">[:,:</span><span class="o">-</span><span class="n">2</span><span class="p">])</span> <span class="o">/</span> <span class="p">(</span><span class="n">2</span><span class="o">*</span><span class="n">dx</span><span class="p">)</span>
    <span class="n">u_y</span> <span class="o">=</span> <span class="p">(</span><span class="n">u</span><span class="p">[</span><span class="n">2</span><span class="p">:,:]</span> <span class="o">-</span> <span class="n">u</span><span class="p">[:</span><span class="o">-</span><span class="n">2</span><span class="p">,:])</span> <span class="o">/</span> <span class="p">(</span><span class="n">2</span><span class="o">*</span><span class="n">dy</span><span class="p">)</span>

    <span class="c"># 2. Compute the Laplacian (Second-order Central Difference)</span>
    <span class="n">lap</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">(</span><span class="n">u</span><span class="p">[:,</span><span class="n">2</span><span class="p">:]</span> <span class="o">-</span> <span class="n">2</span><span class="o">*</span><span class="n">u</span><span class="p">[:,</span><span class="n">1</span><span class="p">:</span><span class="o">-</span><span class="n">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[:,:</span><span class="o">-</span><span class="n">2</span><span class="p">])</span> <span class="o">/</span> <span class="n">dx</span><span class="o">**</span><span class="n">2</span> <span class="o">+</span>
        <span class="p">(</span><span class="n">u</span><span class="p">[</span><span class="n">2</span><span class="p">:,:]</span> <span class="o">-</span> <span class="n">2</span><span class="o">*</span><span class="n">u</span><span class="p">[</span><span class="n">1</span><span class="p">:</span><span class="o">-</span><span class="n">1</span><span class="p">,:]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[:</span><span class="o">-</span><span class="n">2</span><span class="p">,:])</span> <span class="o">/</span> <span class="n">dy</span><span class="o">**</span><span class="n">2</span>
    <span class="p">)</span>

    <span class="c"># 3. Explicit Time Stepping</span>
    <span class="k">return</span> <span class="n">u</span><span class="p">[</span><span class="n">1</span><span class="p">:</span><span class="o">-</span><span class="n">1</span><span class="p">,</span><span class="n">1</span><span class="p">:</span><span class="o">-</span><span class="n">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">dt</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">u</span><span class="p">[</span><span class="n">1</span><span class="p">:</span><span class="o">-</span><span class="n">1</span><span class="p">,</span><span class="n">1</span><span class="p">:</span><span class="o">-</span><span class="n">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">u_x</span> <span class="o">+</span> <span class="n">u_y</span><span class="p">)</span> <span class="o">+</span> <span class="n">nu</span> <span class="o">*</span> <span class="n">lap</span><span class="p">)</span>
</code></pre>

  <hr>

  <h2>3. Dataset Engineering: Managing 819K Points</h2>

  <p>
    This FDM solver generates extremely high-fidelity data. However, storing every pixel at every time step results in an explosion of data. For our training setup, this resulted in an <b>819,200-point spatiotemporal dataset</b>.
  </p>

  <p>
    Feeding 819,200 coordinates into a GPU simultaneously will instantly cause an Out-of-Memory (OOM) error. We constructed a PyTorch <code>Dataset</code> that chunks the data intelligently.
  </p>

  <div class="highlight-box">
    <b>The Chunking Optimization:</b> Instead of passing the whole domain to the trunk network, we split the 819K coordinates into over <b>20,000 discrete chunks</b> during training. This keeps the VRAM usage flat while allowing the network to sweep across the entire spatiotemporal volume efficiently.
  </div>

  <hr>

  <h2>4. The Crux: Why DeepONet instead of a U-Net?</h2>

  <p>
    If we are mapping a 2D grid (initial condition) to another 2D grid (future state), you might ask: <i>"Why not just use a standard Image-to-Image network, like a U-Net?"</i>
  </p>

  <p>
    Here is the fundamental limitation of standard CNNs: <b>They are tied to their grid resolution.</b> If you train a U-Net on $64 \times 64$ grids, it learns to map to a $64 \times 64$ grid at a fixed time step. If you later want to query the solution at a continuous sub-pixel location or an arbitrary continuous time step, the U-Net cannot help you without messy mathematical interpolations.
  </p>

  <p>
    <b>DeepONets represent a paradigm shift: Mesh-Free Operator Learning.</b> 
  </p>

  <p>
    Instead of predicting a grid of pixels, a DeepONet learns the continuous mathematical function itself. It separates the problem into two distinct questions:
  </p>
  <ol>
    <li><b>The Branch:</b> "What universe are we in?" (Looking at the initial condition $u_0$).</li>
    <li><b>The Trunk:</b> "Where exactly are we looking?" (Evaluating the specific coordinates $x, y, t$).</li>
  </ol>
  <p>
    Because the Trunk takes continuous floating-point coordinates as input, the trained model is <i>resolution invariant</i>.
  </p>

  <hr>

  <h2>5. The Branch Network: The Spatial Encoder</h2>

  <p>
    Because the input $u_0$ is a 2D grid, we use a CNN to extract features. However, the magic happens at the <code>AdaptiveAvgPool2d</code> layer. We aggressively bottleneck the network, compressing the feature maps down to a specific latent dimension vector (let's call it $p$).
  </p>

<pre><code class="language-python"><span class="k">class</span> <span class="n">BranchNet</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="n">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="n">14</span><span class="p">):</span> 
        <span class="n">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">convs</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">1</span><span class="p">,</span> <span class="n">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">1</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="p">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">16</span><span class="p">,</span> <span class="n">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">1</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="p">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">2</span><span class="p">),</span>
        <span class="p">)</span>
        
        <span class="c"># Decouples the network from the exact input grid size</span>
        <span class="n">self</span><span class="p">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="n">2</span><span class="p">,</span> <span class="n">2</span><span class="p">))</span>
        
        <span class="c"># Final projection to the latent basis</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">32</span> <span class="o">*</span> <span class="n">2</span> <span class="o">*</span> <span class="n">2</span><span class="p">,</span> <span class="n">64</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">64</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span> 
        <span class="p">)</span>

    <span class="k">def</span> <span class="n">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">convs</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre>

  <hr>

  <h2>6. The Trunk Network: The Coordinate Mapper</h2>

  <p>
    Notice the activation function: we use <b>Tanh</b> instead of ReLU. A neural network with ReLU activations is piecewise linear, meaning its second derivative is zero everywhere (and undefined at the hinges). Since the Burgers equation relies on a smooth second spatial derivative, we must use a smooth, continuously differentiable activation function like Tanh to ensure the learned operator respects the physical continuity of fluid flow. 
  </p>

<pre><code class="language-python"><span class="k">class</span> <span class="n">TrunkNet</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="n">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="n">3</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="n">128</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="n">14</span><span class="p">):</span>
        <span class="n">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Tanh</span><span class="p">(),</span> <span class="c"># Smooth activations for continuous physics</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Tanh</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span> <span class="c"># Must match Branch output dim</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="n">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">coords</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">net</span><span class="p">(</span><span class="n">coords</span><span class="p">)</span>
</code></pre>

  <hr>

  <h2>7. The DeepONet Forward Pass: The Dot Product</h2>

  <p>
    The prediction at any point in space and time is simply the dot product of the Branch output (coefficients $b$) and Trunk output (basis functions $t$): $u(x,y,t) = b \cdot t$.
  </p>

  <h3>Shape Sanity Check: Tracing the Tensors</h3>
  <p>
    To truly understand the forward pass, let's trace a single batch through the network. Imagine a batch size of <code>B = 32</code>, evaluating <code>N = 1000</code> spatiotemporal points per batch.
  </p>

  <pre><code><span class="c"># 1. The Branch Input</span>
u0.shape      <span class="c"># -> [32, 1, 64, 64] (Batch of 32 initial conditions)</span>
branch_out    <span class="c"># -> [32, 14]        (Compressed to 14 latent coefficients)</span>

<span class="c"># 2. The Trunk Input</span>
coords.shape  <span class="c"># -> [32, 1000, 3]   (32 batches, 1000 points, 3 dims: x, y, t)</span>
trunk_out     <span class="c"># -> [32, 1000, 14]  (Mapped to 14 basis functions per point)</span>

<span class="c"># 3. The Alignment</span>
<span class="c"># We expand the branch output to align with the points dimension.</span>
branch_out = branch_out.unsqueeze(1)  <span class="c"># -> [32, 1, 14]</span>

<span class="c"># 4. The Dot Product</span>
<span class="c"># PyTorch broadcasts the Branch output across the 1000 points.</span>
pred = torch.sum(branch_out * trunk_out, dim=-1) <span class="c"># -> [32, 1000]</span>
</code></pre>

  <hr>

  <h2>8. Tracking the Loss: What Does 0.0055 MSE Actually Mean?</h2>

  <p>
    We train the network using the Adam optimizer to minimize the Mean Squared Error (MSE) against the FDM ground truth.
  </p>

  <img src="assets/figures/loss_snapshot.png" alt="Training Loss Snapshot showing MSE over epochs" />
  <div class="image-caption">Figure 1: Command line output snapshot tracking the MSE loss reduction across training epochs.</div>

  <p>
    The loss here is the Mean Squared Error (MSE) between the DeepONet's predicted spatiotemporal field and the ground truth generated by the finite difference solver. When we look at the training log snapshot, we typically see a rapid initial descent followed by a long, slow plateau of marginal improvements. 
  </p>
  <p>
    In the context of the Burgers equation, that initial sharp drop corresponds to the network learning the basic, macroscopic convective behavior—essentially getting the smooth "flow" right. However, the long tail where the loss slowly grinds down to our final minimum of <b>0.0055</b> is where the real mathematical heavy lifting happens. During these later epochs, the network is agonizing over the high-frequency spatial details, specifically the sharp shock fronts. Because the MSE calculation squares the differences, it heavily penalizes large localized errors. To minimize this, the network is forced to optimally allocate the limited capacity of its basis functions—derived from our trunk network—to resolve the exact coordinates where the wave steepens. 
  </p>
  <p>
    Achieving a validation MSE of less than <b>0.1%</b> confirms that the model hasn't just memorized the training grid; it has successfully learned the continuous partial differential operator, balancing nonlinear convection and viscous diffusion across entirely unseen fluid states.
  </p>

  <hr>

  <h2>9. Visualizing the Operator's Performance</h2>

  <img src="assets/figures/prediction.png" alt="DeepONet Predictions 4x4 Grid" />
  <div class="image-caption">Figure 2: A 4x4 grid comparing the Ground Truth (top row) with the DeepONet continuous prediction (bottom row) at various time steps $t$. Notice how accurately the network predicts the steepening of the wave front over time.</div>

  <img src="assets/figures/error.png" alt="DeepONet MAE and L2 Error Maps" />
  <div class="image-caption">Figure 3: Absolute Error maps. Darker colors indicate higher error. The visualization reveals that the vast majority of the domain has near-zero error.</div>

  <h3>What the Visualizations Tell Us</h3>
  <p>
    When you examine the error grids, a clear pattern emerges: the DeepONet's predictions are virtually flawless in the smooth regions of the fluid. The L2 and Mean Absolute Error (MAE) spike <em>exclusively</em> along the shock fronts. It proves our network is actively attempting to balance the physical tension between convection and diffusion, struggling only where the underlying mathematics itself approaches a singularity.
  </p>

  <hr>

  <h2>10. Next Steps: Moving to Spherical Geometries</h2>

  <p>
    Solving the 1+2D Burgers equation on a Euclidean grid is a powerful proof of concept for neural operators. But many real-world physical systems—like global weather patterns or plasma containment—do not exist on flat planes.
  </p>
  <p>
    Our current research at the University of Manchester is expanding this architecture. We are replacing the standard Euclidean CNN branch with $SO(3)$-equivariant Spherical CNNs to solve intrinsic geometric PDEs, specifically the Laplace-Beltrami and Heat equations, directly on the surface of a two-sphere ($\mathbb{S}^2$).
  </p>

</body>
</html>
